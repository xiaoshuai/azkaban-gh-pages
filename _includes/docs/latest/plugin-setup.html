<h2 id="plugin-setup">Set up Azkaban Plugins</h2>

Azkaban is designed to make non-core functionalities plugin-based, so that

<ol>
	<li>they can be selectively installed/upgraded in different environments without changing the core Azkaban, and</li>
	<li>it makes Azkaban very easy to be extended for different systems.</li>
</ol>

<p>Right now, Azkaban allows for a number of different plugins. On web server side, there are</p>
<ul>
	<li>viewer plugins that enable custom web pages to add features to Azkaban. Some of the known implementations include HDFS filesystem viewer, and Reportal.</li>
	<li>trigger plugins that enable custom triggering methods.</li>
	<li>user manager plugin that enables custom user authentication methods. For instance, in LinkedIn we have LDAP based user authentication.</li>
	<li>alerter plugins that enable different alerting methods to users, in addition to email based alerting.</li>
</ul>

<p>On executor server side</p>
<ul>
	<li>pluggable job type executors on AzkabanExecutorServer, such as job types for hadoop ecosystem components.</li>
</ul>

<p>We recommend installing these plugins for the best usage of Azkaban. A set of common plugins are available to download from the <a href="{{ site.home }}/downloads.html">download page</a>. Alternatively, by cloning the <a href="https://github.com/azkaban/azkaban-plugins">GitHub repo</a>, you can run <code>ant</code> in different plugin directories to create tar ball packages.</p>

<p>Below are instructions of how to install these plugins to work with Azkaban.</p>

<h3>User Manager Plugins</h3>
<p>By default, Azkaban ships with the XMLUserManager class which authenticates users based on a xml file, which is located at <code>conf/azkaban-users.xml</code>.</p>
<p>This is not secure and doesn't serve many users. In real production deployment, you should rely on your own user manager class that suits your need, such as a LDAP based one. The <code>XMLUserManager</code> can still be used for special user accounts and managing user roles. You can find examples of these two cases in the default <code>azkaban-users.xml</code> file.</p>

<p>To install your own user manager class, specify in <code>Azkaban2-web-server-install-dir/conf/azkaban.properties</code>:</p>

<pre>user.manager.class=MyUserManagerClass</pre>

<p>and put the containing jar in <code>plugins</code> directory.</p>

<h3>Viewer Plugins</h3>

<h4>HDFS Viewer Plugins</h4>

<p>HDFS Viewer Plugin should be installed in AzkabanWebServer plugins directory, which is specified in AzkabanWebServer's config file, for example, in <code>Azkaban2-web-server-install-dir/conf/azkaban.properties</code>:</p>

<pre>viewer.plugins=hdfs</pre>

<p>This tells Azkaban to load hdfs viewer plugin from <code>Azkaban2-web-server-install-dir/plugins/viewer/hdfs</code>.</p>

<p>Extract the <code>azkaban-hdfs-viewer</code> archive to the AzkabanWebServer <code>./plugins/viewer</code> directory. Rename the directory to <code>hdfs</code>, as specified above.</p>

<p>Depending on if the hadoop installation is turned on:</p>
<ol>
  <li>If the Hadoop installation does not have security turned on, the default config is good enough. One can simply restart <code>AzkabanWebServer</code> and start using the HDFS viewer.</li>
	<li>If the Hadoop installation does have security turned on, the following configs should be set differently than their default values, in plugin's config file:</li>
</ol>

<table class="table table-bordered table-condensed table-striped">
	<thead>
		<tr>
			<th>Parameter</th>
			<th>Description</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td><code>azkaban.should.proxy</code></td>
			<td>Whether Azkaban should proxy as another user to view the hdfs filesystem, rather than Azkaban itself, defaults to <code>true</code></td>
		</tr>
		<tr>
			<td><code>hadoop.security.manager.class</code></td>
			<td>The security manager to be used, which handles talking to secure hadoop cluster, defaults to <code>azkaban.security.HadoopSecurityManager_H_1_0</code> (for hadoop 1.x versions)</td>
		</tr>
		<tr>
			<td><code>proxy.user</code></td>
			<td>The Azkaban user configured with kerberos and hadoop. Similar to how oozie should be configured, for secure hadoop installations</td>
		</tr>
		<tr>
			<td><code>proxy.keytab.location</code></td>
			<td>The location of the keytab file with which Azkaban can authenticate with Kerberos for the specified <code>proxy.user</code></td>
		</tr>
	</tbody>
</table>

<p>For more Hadoop security related information, see <a href="#hadoopsecuritymanager">HadoopSecurityManager</a></p>

<h3>Job Type Plugins</h3>

<p>Azkaban has a limited set of built-in job types to run local unix commands and simple java programs. In most cases, you will want to install additional job type plugins, for example, hadoopJava, Pig, Hive, VoldemortBuildAndPush, etc. Some of the common ones are included in azkaban-jobtype archive. Here is how to install:</p>

<p>Job type plugins should be installed with AzkabanExecutorServer's plugins directory, and specified in AzkabanExecutorServer's config file. For example, in <code>Azkaban2-exec-server-install-dir/conf/azkaban.properties</code>:</p>

<pre>azkaban.jobtype.plugin.dir=plugins/jobtypes</pre>

<p>This tells Azkaban to load all job types from <code>Azkaban2-exec-server-install-dir/plugins/jobtypes</code>. Extract the archive into AzkabanExecutorServer <code>./plugins/</code> directory, rename it to <code>jobtypes</code> as specified above.</p>

<p>The following setting is often needed when you run Hadoop Jobs:</p>

<table class="table table-bordered table-condensed table-striped">
	<thead>
		<tr>
			<th>Parameter</th>
			<th>Description</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td><code>hadoop.home</code></td>
			<td>Your <code>$HADOOP_HOME</code> setting.</td>
		</tr>
		<tr>
			<td><code>jobtype.global.classpath</code></td>
			<td>The cluster specific hadoop resources, such as hadoop-core jar, and hadoop conf (e.g. <code>${hadoop.home}/hadoop-core-1.0.4.jar,${hadoop.home}/conf</code>)</td>
		</tr>
	</tbody>
</table>

Depending on if the hadoop installation is turned on:

<ul>
  <li>If the hadoop installation does not have security turned on, you can likely rely on the default settings.</li>
  <li>If the Hadoop installation does have kerberos authentication turned on, you need to fill out the following hadoop settings:</li>
</ul>

<table class="table table-bordered table-condensed table-striped">
	<thead>
		<tr>
			<th>Parameter</th>
			<th>Description</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td><code>hadoop.security.manager.class</code></td>
			<td>The security manager to be used, which handles talking to secure hadoop cluster, defaults to <code>azkaban.security.HadoopSecurityManager_H_1_0</code> (for hadoop 1.x versions)</td>
		</tr>
		<tr>
			<td><code>proxy.user</code></td>
			<td>The Azkaban user configured with kerberos and hadoop. Similar to how oozie should be configured, for secure hadoop installations</td>
		</tr>
		<tr>
			<td><code>proxy.keytab.location</code></td>
			<td>The location of the keytab file with which Azkaban can authenticate with Kerberos for the specified proxy.user</td>
		</tr>
	</tbody>
</table>

<p>For more Hadoop security related information, see <a href="#hadoopsecuritymanager">HadoopSecurityManager</a></p>

Finally, start the executor, watch for error messages and check executor server log. For job type plugins, the executor should do minimum testing and let you know if it is properly installed.
